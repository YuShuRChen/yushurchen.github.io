---
---

@unpublished{llmath,
  author="Chen, Yu-Shu",
  title="A Study of LLMs' Ability to Perform Basic Math Operations in Different Bases",
  year="2024",

  abstract={Large Language Models have demonstrated remarkable proficiency in a variety of natural language processing tasks, including translation, question-answering, and fill-in-the-blank exercises, with some evidence of reasoning abilities. In this paper, I explore their mathematical reasoning abilities through their performance on simple mathematical tasks. By evaluating GPT-3.5 turbo and GPT-4o on tasks involving addition, subtraction, and multiplication in uncommon numerical bases, this study aims to shed light on the models' ability to generalize to unfamiliar data and their underlying reasoning potential. The results offer insights into the strengths and limitations of LLMs in performing arithmetic operations outside the familiar base-10 system, contributing to a deeper understanding of their reasoning capacities. },
  preview={llmath.jpg},
  code={https://github.com/YuShuRChen/llmath.git},
  pdf={A_Study_of_Large_Language_Models__Ability_to_Perform_Basic_Math_Operations_in_Different_Bases.pdf},
  selected={true},
}

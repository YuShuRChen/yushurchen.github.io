---
---

@unpublished{llmath,
  author="Chen, Yu-Shu",
  title="A Study of LLMs' Ability to Perform Basic Math Operations in Different Bases",
  year="2024",

  abstract={Large Language Models have demonstrated remarkable proficiency in a variety of natural language processing tasks, including translation, question-answering, and fill-in-the-blank exercises, with some evidence of reasoning abilities. In this paper, I explore their mathematical reasoning abilities through their performance on simple mathematical tasks. By evaluating GPT-3.5 turbo and GPT-4o on tasks involving addition, subtraction, and multiplication in uncommon numerical bases, this study aims to shed light on the models' ability to generalize to unfamiliar data and their underlying reasoning potential. The results offer insights into the strengths and limitations of LLMs in performing arithmetic operations outside the familiar base-10 system, contributing to a deeper understanding of their reasoning capacities. },
  preview={llmath.jpg},
  blog={https://yushurchen.github.io/projects/llmath/},
  pdf={A_Study_of_Large_Language_Models__Ability_to_Perform_Basic_Math_Operations_in_Different_Bases.pdf},
  selected={true}
}

@unpublished{isnn,
  author="Chen, Yu-Shu and Meza, Andy",
  title="Interpretable Spiking Neural Network for Basic Mathematical Operations",
  note="Preparing for submission to ICML 2025",
  year="2024",

  abstract={This project focuses on the integration of memory as a crucial component in logical reasoning tasks, particularly in arithmetic. I am investigating several neural architectures that emulate human memory systems, with the current emphasis on developing a spiking neural network (SNN) designed to function as a declarative memory network. This network serves as a long-term memory system capable of storing and recalling single-digit arithmetic operations. The overarching goal of this work is to integrate the declarative memory network with a procedural memory network, forming a larger, cohesive system. This integrated system aims to perform arithmetic tasks logically by leveraging declarative knowledge for fact retrieval and procedural reasoning for computation. Through this project, I aim to better understand the role of memory in reasoning and explore how biologically inspired networks, like SNNs, can be applied to enhance artificial intelligence systems' capacity for logical reasoning and task generalization. },
  blog={https://yushurchen.github.io/projects/isnn/},
  selected={true}
}

@misc{holmes,
  author="Meza, Andy and Chen, Yu-Shu and Nwughala, Chima Tochukwu",
  title="HoLmeS: Design Space Exploration for High-Level Synthesis",
  year="2025",

  blog={https://yushurchen.github.io/projects/holmes/},
  selected={true}
}

@misc{cv4pid,
  author="Meza, Andy and Chen, Yu-Shu and Kaufhold, Stephan",
  title="Computer Vision for Primate Identification",
  year="2025",

  blog={https://yushurchen.github.io/projects/cv4pid/},
  selected={true}
}
